{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BandaVallary/Movie_Recommendation_System/blob/kelvin/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFoeZuR6p4N1"
      },
      "source": [
        "# Movie Recommendation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LStIpYEp4N3"
      },
      "source": [
        "![\"Image of Donald Draper in a Movie Theater\"](https://github.com/BandaVallary/Movie_Recommendation_System/blob/kelvin/images/dondraperinmovietheater.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj7PA39cp4N4"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjW0pm7_p4N5"
      },
      "source": [
        "This project aims to develop a recommendation system that provides personalized movie recommendations based on user ratings. Utilizing the [MovieLens dataset](https://web.archive.org/web/20240828133414/https://grouplens.org/datasets/movielens/latest/) from the GroupLens research lab at the University of Minnesota, the model will be trained on a subset of the dataset containing 100,000 user ratings. The primary objective is to build a machine learning model that can accurately recommend the top 5 movies to a user, based on their ratings of other movies. This system can be valuable for streaming platforms and movie enthusiasts, offering tailored movie suggestions to enhance user experience and engagement.\n",
        "\n",
        "The project will involve several steps, including data cleaning, exploratory data analysis, feature engineering, model selection, and evaluation.\n",
        "\n",
        "Throughout this project, we will also explore the relationships between different variables and their impact on movie recommendations. This will help us gain insights into user preferences and identify potential areas for improvement. Overall, this project has the potential to provide valuable insights and practical applications for the entertainment industry. By developing a recommendation system that can accurately suggest movies, streaming platforms can better engage their users, improve customer satisfaction, and increase viewership."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDeHSVfGp4N6"
      },
      "source": [
        "## Business Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWxuwoaBp4N7"
      },
      "source": [
        "The entertainment industry, particularly streaming platforms, is highly competitive, with companies constantly striving to enhance user engagement and satisfaction. One of the major challenges faced by these platforms is providing personalized content recommendations that keep users engaged and reduce churn rates.\n",
        "\n",
        "According to recent studies, personalized recommendations can significantly increase user engagement and satisfaction, leading to higher retention rates and increased viewership. This highlights the need for a robust recommendation system that can accurately suggest movies based on user preferences. By building a recommendation system that can provide top 5 movie recommendations to users based on their ratings of other movies, streaming platforms can offer a more tailored viewing experience.\n",
        "\n",
        "The business value of this project lies in its ability to help streaming platforms improve their content recommendation strategies, increase user satisfaction, and reduce churn rates. By developing a recommendation system that can accurately suggest movies, platforms can better engage their users, leading to increased viewership and subscription renewals. This can provide a competitive edge in the highly competitive entertainment industry, ultimately driving revenue growth and customer loyalty."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QKSmyNiqABo",
        "outputId": "8529e28a-7413-42f1-e3a8-847c9ed7816b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/154.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357280 sha256=4060e577681d1841d42b6e3660c3cd823c66b820d49f0dd1e5125e637653a93c\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gntIigRVp4N8"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise.prediction_algorithms import SVD\n",
        "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
        "from surprise.model_selection import GridSearchCV\n",
        "from surprise import Reader, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFoMCqqbp4N9"
      },
      "source": [
        "## Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1hUpnwrUp4N-"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "movies = pd.read_csv('/content/movies.csv')\n",
        "ratings = pd.read_csv('/content/ratings.csv')\n",
        "tags = pd.read_csv('/content/tags.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D25vNyX0p4N-"
      },
      "source": [
        "## Tidying the data (ratings df)\n",
        "\n",
        "1. Check data types and figure out which figures are numerical and which are categorical.\n",
        "2. Check for null values.\n",
        "3. Check for duplicate values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou09pjcnp4N_"
      },
      "source": [
        "I check for null values in the dataset. There are none."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "0XWl_SXrp4N_",
        "outputId": "091c2f3d-c766-49f9-a5d5-080f6889dabc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId       0\n",
              "movieId      0\n",
              "rating       0\n",
              "timestamp    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# checking for null values\n",
        "ratings.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOsoqj-Xp4OA"
      },
      "source": [
        "I then check for duplicates. There are none."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn9SPwF8p4OB",
        "outputId": "91eb0216-ce44-4679-c6f9-91dcf1e821ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check for duplicates\n",
        "ratings.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "DgeLcZDFp4OC",
        "outputId": "1de2c947-13ee-4dac-c857-75dcbd99d7ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId         int64\n",
              "movieId        int64\n",
              "rating       float64\n",
              "timestamp      int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>userId</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieId</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# check data types\n",
        "ratings.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3eHYMnvpp4OD"
      },
      "outputs": [],
      "source": [
        "# Drop the timestamp column\n",
        "ratings.drop('timestamp', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wp1rLInp4OD"
      },
      "source": [
        "Now, I'll add the `title` column from the `movies` dataframe to the `ratings` dataframe based on the common `movieId` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WuRJm5qUp4OE"
      },
      "outputs": [],
      "source": [
        "# extracting the title from the `movies` df based on the `movieId`\n",
        "ratings_with_titles = ratings.merge(movies[['movieId', 'title']], on='movieId', how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q3_t04Vp4OE"
      },
      "source": [
        "I'm starting with the `ratings_with_titles` df for my basic recommendation model because it contains key user-item interactions, which are essential for collaborative filtering. This dataframe shows which users rated which movies and their ratings, allowing me to identify patterns in preferences.\n",
        "\n",
        "I'll use collaborative filtering, focusing on either:\n",
        "\n",
        "- User-Based: Recommending movies based on the preferences of similar users.\n",
        "- Item-Based: Suggesting movies based on similarities between items that users have liked.\n",
        "\n",
        "Using `ratings_with_titles` gives me a solid foundation for identifying these relationships, and I can later integrate `movies` and `tags` dataframes for more nuanced recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IaCwcO_p4OE"
      },
      "source": [
        "Now, I'll create a scikit surprise dataset from the `ratings` dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z11ZRQSOp4OF"
      },
      "outputs": [],
      "source": [
        "# reading the values as scikit surprise dataset\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "trainset = data.build_full_trainset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lTLE2rctp4OF"
      },
      "outputs": [],
      "source": [
        "# parameter grid for SVD\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.002, 0.005],\n",
        "    'reg_all': [0.4, 0.6]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b5JItz1p4OG",
        "outputId": "0bc003e8-d0b8-4f74-aba5-a596c0636fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   16.1s\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.1min finished\n"
          ]
        }
      ],
      "source": [
        "# create the grid search object\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, joblib_verbose=5, n_jobs=-1)\n",
        "gs.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qtgxVbwp4OG",
        "outputId": "48075807-4e61-414c-9142-4c4408f8f655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rmse': 0.8834726804864169, 'mae': 0.6825169425864511}\n",
            "{'rmse': {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.4}, 'mae': {'n_factors': 50, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.4}}\n"
          ]
        }
      ],
      "source": [
        "# Get the best parameters\n",
        "print(gs.best_score)\n",
        "print(gs.best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaeILlkJp4OH",
        "outputId": "9f56ffbc-9536-442f-eef2-a1b9a09dea77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.9125338724480567\n",
            "Best MAE: 0.7017337030146399\n",
            "Best Parameters: {'k': 60, 'min_k': 3, 'sim_options': {'name': 'msd', 'user_based': False}}\n"
          ]
        }
      ],
      "source": [
        "# Cross validation with KNNBasic\n",
        "# Parameter grid for KNNBasic\n",
        "param_grid = {\n",
        "    'k': [20, 40, 60],\n",
        "    'min_k': [1, 2, 3],\n",
        "    'sim_options': {\n",
        "        'name': ['cosine', 'msd', 'pearson'],\n",
        "        'user_based': [True, False]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fit the data\n",
        "gs.fit(data)\n",
        "\n",
        "# Get the best parameters and scores\n",
        "print(\"Best RMSE:\", gs.best_score['rmse'])\n",
        "print(\"Best MAE:\", gs.best_score['mae'])\n",
        "print(\"Best Parameters:\", gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These 2 code cells run faster than the cell above\n",
        "\n",
        "# Cross validation with KNNBasic\n",
        "# knn_basic = KNNBasic(sim_options={'name':'msd', 'user_based':True})\n",
        "# cv_knn_basic = cross_validate(knn_basic, data, n_jobs=-1)\n",
        "\n",
        "# and this\n",
        "# Average RMSE\n",
        "# for i in cv_knn_basic.items():\n",
        "#     print(i)\n",
        "# print('-----------------------')\n",
        "# print(np.mean(cv_knn_basic['test_rmse']))"
      ],
      "metadata": {
        "id": "hhW_lM2szXzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_baseline = KNNBaseline(sim_options={'name':'msd', 'user_based':True})\n",
        "cv_knn_baseline = cross_validate(knn_baseline,data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx3rNldT0kak",
        "outputId": "34215503-9ea6-4a92-bf99-2e7131d74209"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the average score for the test set\n",
        "for i in cv_knn_baseline.items():\n",
        "    print(i)\n",
        "\n",
        "np.mean(cv_knn_baseline['test_rmse'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDF4VQmO0xdr",
        "outputId": "c940abf5-17c7-4fe8-ac47-dff6e5ab5509"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('test_rmse', array([0.86696806, 0.88212196, 0.87137691, 0.87282619, 0.87868555]))\n",
            "('test_mae', array([0.66206073, 0.67227165, 0.66788844, 0.66811934, 0.6714491 ]))\n",
            "('fit_time', (0.5258605480194092, 0.5425300598144531, 0.5330810546875, 0.5218255519866943, 0.5999324321746826))\n",
            "('test_time', (1.921116828918457, 1.7216105461120605, 1.6934607028961182, 1.7754650115966797, 2.6083710193634033))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8743957317789242"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based off these outputs, it seems like the best performing model is the SVD model with n_factors = 100 and a regularization rate of 0.4."
      ],
      "metadata": {
        "id": "zGS_Lj752YmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I'll create a `get_movie_recommendations` function that is designed to enhance the user experience by allowing users to provide ratings for a selection of movies they've seen. It prompts users to rate five randomly chosen movies on a scale of 0.5 to 5. If a user hasn't watched a particular movie, they can simply enter 'n' to skip it.\n",
        "\n",
        "After collecting the ratings, the function uses a trained recommendation model to predict ratings for all movies in the dataset. It then adjusts the predicted ratings based on the user's inputs and recommends the top movies tailored to their preferences. This approach ensures that users receive personalized suggestions that align with their tastes."
      ],
      "metadata": {
        "id": "-z0DAkIIk1fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_recommendations(user_id, ratings_with_titles, model, n_recommendations=5):\n",
        "    # Prepare a sample of movies to prompt the user\n",
        "    sample_movies = ratings_with_titles.sample(n=5)\n",
        "    print(\"Please rate the following movies on a scale of 0.5 to 5 (or enter 'n' to skip):\")\n",
        "\n",
        "    user_ratings = {}\n",
        "\n",
        "    for index, row in sample_movies.iterrows():\n",
        "        title = row['title']\n",
        "        # Prompt user for rating\n",
        "        rating_input = input(f\"Rate '{title}': \")\n",
        "\n",
        "        if rating_input.lower() == 'n':\n",
        "            continue  # Skip this movie if the user hasn't seen it\n",
        "\n",
        "        try:\n",
        "            rating = float(rating_input)\n",
        "            user_ratings[row['movieId']] = rating\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number between 0.5 and 5 or 'n' to skip.\")\n",
        "\n",
        "    # Get predictions for all movies\n",
        "    all_movie_ids = ratings_with_titles['movieId'].unique()\n",
        "    predictions = []\n",
        "\n",
        "    for movie_id in all_movie_ids:\n",
        "        # Use the model to predict the rating\n",
        "        pred_rating = model.predict(user_id, movie_id).est\n",
        "\n",
        "        # If the user rated this movie, adjust the prediction based on their rating\n",
        "        if movie_id in user_ratings:\n",
        "            adjusted_rating = (pred_rating + user_ratings[movie_id]) / 2\n",
        "        else:\n",
        "            adjusted_rating = pred_rating\n",
        "\n",
        "        predictions.append((movie_id, adjusted_rating))\n",
        "\n",
        "    # Sort predictions by adjusted rating\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Recommend top N movies\n",
        "    recommended_movies = predictions[:n_recommendations]\n",
        "\n",
        "    # Convert movie IDs to titles\n",
        "    recommended_titles = ratings_with_titles[ratings_with_titles['movieId'].isin([m[0] for m in recommended_movies])]\n",
        "\n",
        "    return recommended_titles[['title', 'movieId']]\n",
        "\n",
        "# Usage\n",
        "user_id = 55  # user ID\n",
        "best_model = gs.best_estimator['rmse']  # or 'mae'\n",
        "best_model.fit(trainset)\n",
        "recommended_movies = get_movie_recommendations(user_id, ratings_with_titles, best_model)\n",
        "print(\"Recommended Movies:\")\n",
        "print(recommended_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdsNKFNABVD4",
        "outputId": "cbc9fcfd-fee3-4995-ad96-7795024f50ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Please rate the following movies on a scale of 0.5 to 5 (or enter 'n' to skip):\n",
            "Rate 'Contact (1997)': 3.9\n",
            "Rate 'Legend of Bagger Vance, The (2000)': 4.0\n",
            "Rate 'Doom (2005)': 4.1\n",
            "Rate 'Mission: Impossible (1996)': 4.2\n",
            "Rate 'Soul Surfer (2011)': 4.3\n",
            "Recommended Movies:\n",
            "                      title  movieId\n",
            "9016   Way Back, The (2010)    83369\n",
            "9139       The Mummy (2017)   170827\n",
            "9147           Black Mirror   176601\n",
            "9153           Alpha (2018)   185031\n",
            "90034            61* (2001)    27373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks"
      ],
      "metadata": {
        "id": "8xnUMSG8U4W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare to build a neural network, I'll merge `movies`, `ratings` and `tags` dataframes to one dataframe. First, I'll merge `movies` and `ratings`."
      ],
      "metadata": {
        "id": "ngrwRTw8H2iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ratings = pd.merge(movies, ratings, on='movieId', how='left')"
      ],
      "metadata": {
        "id": "MPxMm3AvITSL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll merge the results with `tags` dataframe."
      ],
      "metadata": {
        "id": "1wEeeIp_TJL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ratings_tags = pd.merge(movies_ratings, tags, on='movieId', how='left')"
      ],
      "metadata": {
        "id": "RqubDhH3TSbi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since two userId columns(userId_x, userId_y) have been created after the merge, we'll drop one userId column."
      ],
      "metadata": {
        "id": "sUyqaKDhVBLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ratings_tags = movies_ratings_tags.drop('userId_y', axis=1)\n",
        "movies_ratings_tags = movies_ratings_tags.rename(columns={'userId_x': 'userId'})"
      ],
      "metadata": {
        "id": "NjBP_APCVgLZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll drop the `timestamp` column:"
      ],
      "metadata": {
        "id": "TI9TGyfaXBc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ratings_tags = movies_ratings_tags.drop('timestamp', axis=1)"
      ],
      "metadata": {
        "id": "4ssVPdZxXZUm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll preprocess the data to create user-item pairs suitable for training our model."
      ],
      "metadata": {
        "id": "fYL0lALoaZas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "wgyG7viVZbh1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user-item interaction matrix\n",
        "ratings = movies_ratings_tags[['userId', 'movieId', 'rating']]"
      ],
      "metadata": {
        "id": "rnmd3jcXZpNe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user and movie mappings\n",
        "user_ids = ratings['userId'].unique()\n",
        "movie_ids = ratings['movieId'].unique()"
      ],
      "metadata": {
        "id": "HA-mzR8XaCFS"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_to_index = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
        "movie_to_index = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}"
      ],
      "metadata": {
        "id": "I0YsBxZYaHlZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert userId and movieId to indices\n",
        "ratings['userIndex'] = ratings['userId'].map(user_to_index)\n",
        "ratings['movieIndex'] = ratings['movieId'].map(movie_to_index)"
      ],
      "metadata": {
        "id": "FAQjw2B5aL1V"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = train[['userIndex', 'movieIndex']]\n",
        "y_train = train['rating']\n",
        "X_test = test[['userIndex', 'movieIndex']]\n",
        "y_test = test['rating']"
      ],
      "metadata": {
        "id": "uSfZQrcqaRch"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}